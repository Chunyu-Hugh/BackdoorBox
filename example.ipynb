{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the example code of benign training and poisoned training on torchvision.datasets.DatasetFolder.\n",
    "Dataset is CIFAR-10.\n",
    "Attack method is BadNets.\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, RandomHorizontalFlip\n",
    "\n",
    "import core\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='./data/cifar10/', train=True, download=True)\n",
    "tes_data = torchvision.datasets.CIFAR10(root='./data/cifar10/', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.45 0.44 0.44 0.45 \n",
      "0.45 0.45 0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.45 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.46 0.46 0.45 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.47 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.46 0.45 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.47 0.46 0.45 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.54 0.60 0.55 0.49 0.45 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.47 0.46 0.45 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.46 0.47 0.47 0.47 0.47 0.55 0.74 0.78 0.76 0.68 0.47 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.46 0.47 0.46 0.45 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.47 0.46 0.49 0.52 0.55 0.60 0.60 0.61 0.58 0.47 0.45 0.45 \n",
      "0.45 0.45 0.45 0.46 0.46 0.47 0.47 0.47 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.46 0.46 0.47 0.48 0.54 0.53 0.51 0.50 0.48 0.47 0.46 0.46 0.45 0.45 0.45 \n",
      "0.45 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.46 0.47 0.48 0.52 0.61 0.62 0.50 0.47 0.45 0.43 0.44 0.47 0.47 0.46 0.46 0.46 \n",
      "0.45 0.46 0.46 0.47 0.47 0.47 0.47 0.48 0.49 0.48 0.48 0.47 0.47 0.47 0.47 0.47 0.48 0.49 0.57 0.63 0.59 0.49 0.42 0.42 0.42 0.43 0.45 0.46 0.47 0.46 0.46 0.46 \n",
      "0.45 0.46 0.46 0.47 0.46 0.47 0.44 0.42 0.46 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.47 0.55 0.65 0.53 0.43 0.39 0.38 0.43 0.49 0.47 0.45 0.45 0.46 0.46 0.46 0.46 \n",
      "0.46 0.46 0.47 0.47 0.44 0.45 0.44 0.38 0.33 0.33 0.39 0.44 0.45 0.47 0.47 0.47 0.30 0.35 0.55 0.44 0.38 0.36 0.40 0.48 0.49 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.46 0.47 0.47 0.48 0.48 0.47 0.46 0.47 0.42 0.32 0.30 0.27 0.27 0.27 0.27 0.34 0.20 0.24 0.45 0.40 0.39 0.45 0.48 0.48 0.47 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.46 0.47 0.47 0.43 0.45 0.53 0.47 0.45 0.46 0.44 0.40 0.31 0.27 0.20 0.23 0.30 0.27 0.27 0.37 0.36 0.43 0.43 0.45 0.47 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.46 0.46 0.47 0.34 0.31 0.45 0.50 0.46 0.46 0.48 0.49 0.56 0.46 0.25 0.25 0.29 0.32 0.37 0.37 0.29 0.33 0.20 0.34 0.48 0.45 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.46 0.48 0.41 0.25 0.26 0.33 0.44 0.48 0.51 0.59 0.64 0.50 0.36 0.28 0.31 0.33 0.33 0.29 0.21 0.26 0.18 0.34 0.49 0.46 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.46 0.47 0.46 0.22 0.14 0.13 0.23 0.48 0.60 0.55 0.48 0.43 0.38 0.34 0.38 0.37 0.29 0.24 0.22 0.32 0.37 0.44 0.48 0.47 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.47 0.49 0.31 0.11 0.13 0.27 0.52 0.53 0.45 0.42 0.38 0.38 0.42 0.46 0.47 0.43 0.35 0.33 0.34 0.46 0.47 0.48 0.47 0.46 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.46 0.44 0.50 0.46 0.30 0.32 0.47 0.49 0.43 0.40 0.37 0.41 0.47 0.49 0.48 0.48 0.48 0.47 0.45 0.44 0.47 0.48 0.48 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.44 0.33 0.33 0.35 0.37 0.42 0.45 0.40 0.38 0.38 0.44 0.50 0.50 0.48 0.48 0.48 0.48 0.48 0.48 0.49 0.48 0.48 0.48 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.44 0.43 0.36 0.33 0.38 0.40 0.42 0.44 0.48 0.49 0.48 0.48 0.48 0.49 0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.47 0.49 0.44 0.42 0.44 0.41 0.48 0.50 0.48 0.47 0.47 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.47 0.47 0.46 0.48 0.49 0.47 0.49 0.48 0.47 0.47 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.47 0.47 0.46 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.47 0.47 0.47 0.47 0.49 0.50 0.49 0.49 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.47 0.47 0.47 0.46 0.46 0.46 0.46 0.46 \n",
      "0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.47 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.47 0.47 0.47 0.46 0.46 0.45 0.45 \n",
      "0.47 0.48 0.48 0.47 0.47 0.47 0.47 0.48 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n",
      "0.47 0.48 0.48 0.47 0.47 0.47 0.48 0.48 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n",
      "0.47 0.47 0.48 0.48 0.48 0.49 0.49 0.48 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n",
      "0.47 0.47 0.47 0.48 0.48 0.48 0.49 0.48 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n",
      "0.53 0.53 0.53 0.53 0.54 0.55 0.55 0.49 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n",
      "0.58 0.58 0.57 0.58 0.59 0.61 0.57 0.49 0.48 0.48 0.48 0.48 0.48 0.48 0.48 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.49 0.48 0.48 0.47 0.47 0.46 0.45 0.45 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = torchvision.datasets.DatasetFolder\n",
    "\n",
    "# image file -> cv.imread -> numpy.ndarray (H x W x C) -> ToTensor -> torch.Tensor (C x H x W) -> RandomHorizontalFlip -> torch.Tensor -> network input\n",
    "transform_train = Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip()\n",
    "])\n",
    "trainset = dataset(\n",
    "    root='./data/cifar10/train/',\n",
    "    loader=cv2.imread,\n",
    "    extensions=('png',),\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    is_valid_file=None)\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "testset = dataset(\n",
    "    root='./data/cifar10/test',\n",
    "    loader=cv2.imread,\n",
    "    extensions=('png',),\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    is_valid_file=None)\n",
    "\n",
    "index = 44\n",
    "\n",
    "x, y = trainset[index]\n",
    "print(y)\n",
    "for a in x[0]:\n",
    "    for b in a:\n",
    "        print(\"%-4.2f\" % float(b), end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is the example code of benign training and poisoned training on torchvision.datasets.DatasetFolder.\n",
    "Dataset is CIFAR-10.\n",
    "Attack method is BadNets.\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, ToTensor, PILToTensor, RandomHorizontalFlip\n",
    "\n",
    "import core\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.DatasetFolder\n",
    "\n",
    "# image file -> cv.imread -> numpy.ndarray (H x W x C) -> ToTensor -> torch.Tensor (C x H x W) -> RandomHorizontalFlip -> torch.Tensor -> network input\n",
    "transform_train = Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip()\n",
    "])\n",
    "trainset = dataset(\n",
    "    root='./data/cifar10/train',\n",
    "    loader=cv2.imread,\n",
    "    extensions=('png',),\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    is_valid_file=None)\n",
    "\n",
    "transform_test = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "testset = dataset(\n",
    "    root='./data/cifar10/test',\n",
    "    loader=cv2.imread,\n",
    "    extensions=('png',),\n",
    "    transform=transform_train,\n",
    "    target_transform=None,\n",
    "    is_valid_file=None)\n",
    "\n",
    "index = 44\n",
    "\n",
    "# x, y = trainset[index]\n",
    "# print(y)\n",
    "# for a in x[0]:\n",
    "#     for b in a:\n",
    "#         print(\"%-4.2f\" % float(b), end=' ')\n",
    "#     print()\n",
    "\n",
    "\n",
    "pattern = torch.zeros((1, 32, 32), dtype=torch.uint8)\n",
    "pattern[0, -3:, -3:] = 255\n",
    "weight = torch.zeros((1, 32, 32), dtype=torch.float32)\n",
    "weight[0, -3:, -3:] = 1.0\n",
    "\n",
    "badnets = core.BadNets(\n",
    "    train_dataset=trainset,\n",
    "    test_dataset=testset,\n",
    "    model=core.models.ResNet(18),\n",
    "    # model=core.models.BaselineMNISTNetwork(),\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    y_target=1,\n",
    "    poisoned_rate=0.05,\n",
    "    pattern=pattern,\n",
    "    weight=weight,\n",
    "    poisoned_transform_train_index=0,\n",
    "    poisoned_target_transform_index=0,\n",
    "    schedule=None,\n",
    "    seed=666\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "        batch_size=128,\n",
    "                shuffle=True,\n",
    "                # num_workers=16,\n",
    "                drop_last=False,\n",
    "                pin_memory=True,\n",
    "                worker_init_fn=88\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[tensor([[[[0.1725, 0.1882, 0.1843,  ..., 0.1882, 0.1804, 0.2157],\n",
      "          [0.0000, 0.0235, 0.0157,  ..., 0.0157, 0.0078, 0.0510],\n",
      "          [0.0078, 0.0353, 0.0275,  ..., 0.0196, 0.0157, 0.0588],\n",
      "          ...,\n",
      "          [0.3686, 0.3961, 0.3922,  ..., 0.2549, 0.0471, 0.0588],\n",
      "          [0.3412, 0.3529, 0.3529,  ..., 0.3216, 0.0824, 0.0471],\n",
      "          [0.4157, 0.4353, 0.4314,  ..., 0.3922, 0.2431, 0.2235]],\n",
      "\n",
      "         [[0.1725, 0.1922, 0.1882,  ..., 0.1882, 0.1804, 0.2157],\n",
      "          [0.0000, 0.0275, 0.0196,  ..., 0.0196, 0.0118, 0.0510],\n",
      "          [0.0118, 0.0431, 0.0353,  ..., 0.0275, 0.0235, 0.0627],\n",
      "          ...,\n",
      "          [0.2471, 0.2941, 0.2902,  ..., 0.2314, 0.0549, 0.0667],\n",
      "          [0.2431, 0.2667, 0.2667,  ..., 0.2784, 0.0824, 0.0510],\n",
      "          [0.3490, 0.3725, 0.3647,  ..., 0.3569, 0.2353, 0.2235]],\n",
      "\n",
      "         [[0.1647, 0.1843, 0.1804,  ..., 0.1843, 0.1765, 0.2078],\n",
      "          [0.0000, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0431],\n",
      "          [0.0000, 0.0196, 0.0157,  ..., 0.0078, 0.0039, 0.0510],\n",
      "          ...,\n",
      "          [0.0824, 0.1255, 0.1176,  ..., 0.1608, 0.0235, 0.0510],\n",
      "          [0.0824, 0.1137, 0.1137,  ..., 0.1647, 0.0431, 0.0392],\n",
      "          [0.2275, 0.2627, 0.2549,  ..., 0.2706, 0.2118, 0.2196]]],\n",
      "\n",
      "\n",
      "        [[[0.4431, 0.4471, 0.4549,  ..., 0.4000, 0.3765, 0.3961],\n",
      "          [0.4431, 0.4510, 0.4588,  ..., 0.4196, 0.4157, 0.4078],\n",
      "          [0.4000, 0.4353, 0.4235,  ..., 0.4471, 0.4471, 0.4431],\n",
      "          ...,\n",
      "          [0.3647, 0.3647, 0.3529,  ..., 0.3451, 0.3608, 0.3294],\n",
      "          [0.3725, 0.3608, 0.3647,  ..., 0.3333, 0.3451, 0.3294],\n",
      "          [0.4118, 0.3765, 0.3765,  ..., 0.2980, 0.3216, 0.3294]],\n",
      "\n",
      "         [[0.5725, 0.5882, 0.5804,  ..., 0.5725, 0.5569, 0.5725],\n",
      "          [0.5647, 0.5804, 0.5843,  ..., 0.5765, 0.5725, 0.5647],\n",
      "          [0.5098, 0.5373, 0.5490,  ..., 0.5765, 0.5765, 0.5725],\n",
      "          ...,\n",
      "          [0.4627, 0.4510, 0.4078,  ..., 0.4667, 0.4941, 0.4706],\n",
      "          [0.4510, 0.4314, 0.4039,  ..., 0.4510, 0.4706, 0.4667],\n",
      "          [0.4588, 0.4314, 0.4196,  ..., 0.3843, 0.4157, 0.4510]],\n",
      "\n",
      "         [[0.2353, 0.2392, 0.2588,  ..., 0.1882, 0.1686, 0.1882],\n",
      "          [0.2431, 0.2471, 0.2510,  ..., 0.2039, 0.2000, 0.1922],\n",
      "          [0.2118, 0.2392, 0.2078,  ..., 0.2314, 0.2314, 0.2314],\n",
      "          ...,\n",
      "          [0.1451, 0.1608, 0.1804,  ..., 0.1294, 0.1725, 0.1608],\n",
      "          [0.1961, 0.2118, 0.2314,  ..., 0.1529, 0.1529, 0.1412],\n",
      "          [0.2510, 0.2471, 0.2588,  ..., 0.1451, 0.1333, 0.1412]]],\n",
      "\n",
      "\n",
      "        [[[0.3725, 0.3608, 0.3725,  ..., 0.5294, 0.5255, 0.4745],\n",
      "          [0.3529, 0.3412, 0.3569,  ..., 0.4902, 0.4431, 0.3294],\n",
      "          [0.3686, 0.3843, 0.3608,  ..., 0.4471, 0.3961, 0.2667],\n",
      "          ...,\n",
      "          [0.4902, 0.4549, 0.4392,  ..., 0.3647, 0.3412, 0.4392],\n",
      "          [0.4431, 0.5059, 0.4784,  ..., 0.3412, 0.3451, 0.3255],\n",
      "          [0.3686, 0.4078, 0.4392,  ..., 0.3333, 0.4000, 0.3216]],\n",
      "\n",
      "         [[0.5020, 0.4941, 0.4902,  ..., 0.6510, 0.6392, 0.6039],\n",
      "          [0.4824, 0.4745, 0.4824,  ..., 0.5961, 0.5569, 0.4667],\n",
      "          [0.5020, 0.5098, 0.4941,  ..., 0.5725, 0.5294, 0.4196],\n",
      "          ...,\n",
      "          [0.5804, 0.5490, 0.4863,  ..., 0.4980, 0.4627, 0.5529],\n",
      "          [0.5373, 0.5961, 0.5137,  ..., 0.4588, 0.4784, 0.4510],\n",
      "          [0.4706, 0.4941, 0.5137,  ..., 0.4275, 0.5373, 0.4667]],\n",
      "\n",
      "         [[0.2824, 0.2824, 0.2627,  ..., 0.5373, 0.5098, 0.4157],\n",
      "          [0.2510, 0.2510, 0.2549,  ..., 0.4314, 0.4510, 0.3333],\n",
      "          [0.2314, 0.2510, 0.2471,  ..., 0.2902, 0.3490, 0.2353],\n",
      "          ...,\n",
      "          [0.3647, 0.2902, 0.4039,  ..., 0.3059, 0.3412, 0.4588],\n",
      "          [0.3255, 0.2941, 0.3843,  ..., 0.2314, 0.3529, 0.3569],\n",
      "          [0.3098, 0.3569, 0.3098,  ..., 0.2353, 0.4078, 0.3490]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3451, 0.3216, 0.3098,  ..., 0.3529, 0.3686, 0.4039],\n",
      "          [0.3725, 0.3765, 0.3529,  ..., 0.3922, 0.4039, 0.4275],\n",
      "          [0.3333, 0.3686, 0.3765,  ..., 0.4314, 0.4392, 0.4431],\n",
      "          ...,\n",
      "          [0.5412, 0.6039, 0.6118,  ..., 0.6000, 0.5294, 0.4745],\n",
      "          [0.6000, 0.6275, 0.5804,  ..., 0.5882, 0.5647, 0.5176],\n",
      "          [0.6078, 0.6392, 0.6078,  ..., 0.5608, 0.5765, 0.5882]],\n",
      "\n",
      "         [[0.2471, 0.2235, 0.2118,  ..., 0.2392, 0.2549, 0.2980],\n",
      "          [0.2706, 0.2706, 0.2471,  ..., 0.2745, 0.2863, 0.3176],\n",
      "          [0.2235, 0.2588, 0.2667,  ..., 0.3059, 0.3176, 0.3255],\n",
      "          ...,\n",
      "          [0.4039, 0.4824, 0.4902,  ..., 0.4588, 0.3843, 0.3216],\n",
      "          [0.4588, 0.4902, 0.4431,  ..., 0.4431, 0.4196, 0.3647],\n",
      "          [0.4627, 0.5020, 0.4745,  ..., 0.4157, 0.4235, 0.4353]],\n",
      "\n",
      "         [[0.2431, 0.2196, 0.2078,  ..., 0.2314, 0.2510, 0.2902],\n",
      "          [0.2627, 0.2667, 0.2431,  ..., 0.2667, 0.2784, 0.3059],\n",
      "          [0.2118, 0.2471, 0.2549,  ..., 0.2902, 0.2980, 0.3098],\n",
      "          ...,\n",
      "          [0.3686, 0.4353, 0.4392,  ..., 0.3961, 0.3216, 0.2627],\n",
      "          [0.4196, 0.4392, 0.3922,  ..., 0.3922, 0.3647, 0.2980],\n",
      "          [0.4157, 0.4549, 0.4314,  ..., 0.3490, 0.3529, 0.3608]]],\n",
      "\n",
      "\n",
      "        [[[0.1176, 0.1725, 0.1176,  ..., 0.1882, 0.1922, 0.1765],\n",
      "          [0.1098, 0.0863, 0.0902,  ..., 0.2275, 0.2510, 0.1922],\n",
      "          [0.1255, 0.0824, 0.0824,  ..., 0.2706, 0.3059, 0.2314],\n",
      "          ...,\n",
      "          [0.6784, 0.6471, 0.7176,  ..., 0.8784, 0.8667, 0.8706],\n",
      "          [0.7176, 0.6588, 0.6314,  ..., 0.8667, 0.8549, 0.8471],\n",
      "          [0.7255, 0.6980, 0.6431,  ..., 0.8471, 0.8549, 0.8471]],\n",
      "\n",
      "         [[0.1922, 0.2627, 0.1882,  ..., 0.2588, 0.2588, 0.2392],\n",
      "          [0.1686, 0.1647, 0.1451,  ..., 0.2941, 0.3137, 0.2549],\n",
      "          [0.1686, 0.1412, 0.1216,  ..., 0.3255, 0.3608, 0.2824],\n",
      "          ...,\n",
      "          [0.6078, 0.5804, 0.6510,  ..., 0.8471, 0.8471, 0.8510],\n",
      "          [0.6431, 0.5843, 0.5529,  ..., 0.8392, 0.8353, 0.8314],\n",
      "          [0.6392, 0.6235, 0.5647,  ..., 0.8314, 0.8431, 0.8353]],\n",
      "\n",
      "         [[0.0941, 0.1922, 0.1529,  ..., 0.1882, 0.1922, 0.1882],\n",
      "          [0.0863, 0.1137, 0.1373,  ..., 0.2235, 0.2431, 0.1961],\n",
      "          [0.0784, 0.0902, 0.1216,  ..., 0.2510, 0.2863, 0.2196],\n",
      "          ...,\n",
      "          [0.4431, 0.4078, 0.4941,  ..., 0.7294, 0.7098, 0.7020],\n",
      "          [0.4902, 0.4275, 0.4157,  ..., 0.7373, 0.7216, 0.6980],\n",
      "          [0.4824, 0.4667, 0.4353,  ..., 0.7255, 0.7333, 0.7176]]],\n",
      "\n",
      "\n",
      "        [[[0.4471, 0.1490, 0.1333,  ..., 0.6588, 0.6510, 0.6353],\n",
      "          [0.1922, 0.0745, 0.1255,  ..., 0.6824, 0.6902, 0.6667],\n",
      "          [0.1765, 0.1176, 0.1333,  ..., 0.6588, 0.6667, 0.6745],\n",
      "          ...,\n",
      "          [0.4392, 0.4510, 0.4235,  ..., 0.6196, 0.6980, 0.7059],\n",
      "          [0.3882, 0.4039, 0.4314,  ..., 0.5451, 0.5843, 0.5490],\n",
      "          [0.4863, 0.4118, 0.4392,  ..., 0.4549, 0.4706, 0.6549]],\n",
      "\n",
      "         [[0.4392, 0.1373, 0.1255,  ..., 0.7098, 0.6980, 0.6588],\n",
      "          [0.1882, 0.0667, 0.0980,  ..., 0.7569, 0.7647, 0.7176],\n",
      "          [0.2039, 0.1412, 0.1137,  ..., 0.7451, 0.7529, 0.7333],\n",
      "          ...,\n",
      "          [0.4392, 0.4627, 0.4549,  ..., 0.5059, 0.5804, 0.5922],\n",
      "          [0.3804, 0.4118, 0.4588,  ..., 0.4510, 0.5098, 0.4980],\n",
      "          [0.4745, 0.4118, 0.4471,  ..., 0.4000, 0.4510, 0.6588]],\n",
      "\n",
      "         [[0.4745, 0.1961, 0.1804,  ..., 0.7686, 0.7608, 0.7020],\n",
      "          [0.2118, 0.1294, 0.1882,  ..., 0.8431, 0.8510, 0.7804],\n",
      "          [0.1922, 0.1647, 0.1922,  ..., 0.8392, 0.8471, 0.8078],\n",
      "          ...,\n",
      "          [0.2471, 0.1725, 0.1569,  ..., 0.3059, 0.3686, 0.4196],\n",
      "          [0.2549, 0.1882, 0.1961,  ..., 0.2784, 0.3176, 0.3569],\n",
      "          [0.4510, 0.3294, 0.3176,  ..., 0.3255, 0.3451, 0.6000]]]]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate( train_loader):\n",
    "    print(i)\n",
    "    print(j)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This machine has 1 cuda devices, and use 1 of them to train.\n",
      "Total train samples: 5000\n",
      "Total test samples: 10000\n",
      "Batch size: 128\n",
      "iteration every epoch: 39\n",
      "Initial learning rate: 0.1\n",
      "\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "poisoned_train_dataset, poisoned_test_dataset = badnets.get_poisoned_dataset()\n",
    "\n",
    "\n",
    "# x, y = poisoned_train_dataset[index]\n",
    "# print(y)\n",
    "# for a in x[0]:\n",
    "#     for b in a:\n",
    "#         print(\"%-4.2f\" % float(b), end=' ')\n",
    "#     print()\n",
    "\n",
    "# x, y = poisoned_test_dataset[index]\n",
    "# print(y)\n",
    "# for a in x[0]:\n",
    "#     for b in a:\n",
    "#         print(\"%-4.2f\" % float(b), end=' ')\n",
    "#     print()\n",
    "\n",
    "# train benign model\n",
    "schedule = {\n",
    "    'device': 'GPU',\n",
    "    'CUDA_VISIBLE_DEVICES': '0',\n",
    "    'GPU_num': 1,\n",
    "\n",
    "    'benign_training': True,\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 16,\n",
    "\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'gamma': 0.1,\n",
    "    'schedule': [150, 180],\n",
    "\n",
    "    'epochs': 5,\n",
    "\n",
    "    'log_iteration_interval': 100,\n",
    "    'test_epoch_interval': 10,\n",
    "    'save_epoch_interval': 10,\n",
    "\n",
    "    'save_dir': 'experiments',\n",
    "    'experiment_name': 'train_benign_DatasetFolder-CIFAR10'\n",
    "}\n",
    "\n",
    "badnets.train(schedule)\n",
    "\n",
    "\n",
    "# train attacked model\n",
    "schedule = {\n",
    "    'device': 'GPU',\n",
    "    'CUDA_VISIBLE_DEVICES': '0',\n",
    "    'GPU_num': 1,\n",
    "\n",
    "    'benign_training': False,\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 16,\n",
    "\n",
    "    'lr': 0.1,\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'gamma': 0.1,\n",
    "    'schedule': [150, 180],\n",
    "\n",
    "    'epochs': 200,\n",
    "\n",
    "    'log_iteration_interval': 100,\n",
    "    'test_epoch_interval': 10,\n",
    "    'save_epoch_interval': 10,\n",
    "\n",
    "    'save_dir': 'experiments',\n",
    "    'experiment_name': 'train_poisoned_DatasetFolder-CIFAR10'\n",
    "}\n",
    "\n",
    "badnets.train(schedule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backdoor_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8624608b71370d57c7079e5a54c452063c6d77bfdb197d64d0401284425cf16e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
